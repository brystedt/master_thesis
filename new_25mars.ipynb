{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reg_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "#from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.applications.resnet import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing data set with dimensions (192, 240)\n",
      "Using normalized coordinates as target.\n",
      "Using single-channel pixels.\n",
      "Importing data...\n",
      "Import complete.\n",
      "Dividing and augmenting data...\n",
      "Dividing data into train and test set.\n",
      "Adding flipped images to trainset.\n",
      "False\n",
      "Adding images with noise to trainset.\n",
      "Making Gauss1\n",
      "Adding Gauss1\n",
      "Making Gauss2\n",
      "Adding Gauss2\n",
      "Data set construction complete.\n"
     ]
    }
   ],
   "source": [
    "dim = (192, 240)\n",
    "#dim = (384, 480)\n",
    "#dim = (576, 720)\n",
    "#dim = (768, 960)\n",
    "#dim = (960, 1200)\n",
    "coord = False\n",
    "rgb = False\n",
    "\n",
    "trainsize = 0.85\n",
    "augment_flip = True\n",
    "augment_noise = 2\n",
    "\n",
    "print(\"Constructing data set with dimensions \" + str(dim))\n",
    "if coord:\n",
    "    print(\"Using coordinate index as target.\")\n",
    "else:\n",
    "    print(\"Using normalized coordinates as target.\")\n",
    "if rgb:\n",
    "    print(\"Using 3-channel pixels.\")\n",
    "else: \n",
    "    print(\"Using single-channel pixels.\")\n",
    "\n",
    "print(\"Importing data...\")\n",
    "X_img, Y_pix = load_data(rgb = rgb, dim = dim, coord = coord)\n",
    "print(\"Import complete.\")\n",
    "print(\"Dividing and augmenting data...\")\n",
    "X_train, Y_train, X_test, Y_test = divide_train_test(X_img, Y_pix, \n",
    "                                                     trainsize = trainsize, rgb = rgb, \n",
    "                                                     augment_flip = augment_flip, augment_noise = augment_noise,\n",
    "                                                     coord = coord)\n",
    "print(\"Data set construction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4464, 240, 192, 1)\n",
      "(4464, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.768359375' '0.5495793269230769']\n",
      " ['0.9251802884615384' '0.62060546875']\n",
      " ['0.9209735576923077' '0.4111328125']\n",
      " ...\n",
      " ['0.8359375' '0.38427734375']\n",
      " ['0.8665865384615384' '0.42138671875']\n",
      " ['0.07481971153846156' '0.5859375']]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9953125\n",
      "0.9948918269230769\n"
     ]
    }
   ],
   "source": [
    "print(np.amax(Y_train.astype(float)))\n",
    "print(np.amax(Y_test.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004687499999999956\n",
      "0.03046875\n"
     ]
    }
   ],
   "source": [
    "print(np.amin(Y_train.astype(float)))\n",
    "print(np.amin(Y_test.astype(float)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n"
     ]
    }
   ],
   "source": [
    "if rgb:\n",
    "    channels = 3\n",
    "else:\n",
    "    channels = 1\n",
    "\n",
    "if dim == (192, 240):\n",
    "    inshape = (240, 192,  channels) \n",
    "elif dim == (384, 480):\n",
    "    inshape = (480, 384, channels)\n",
    "elif dim == (576, 720):\n",
    "    inshape = (720, 576, channels)\n",
    "elif dim == (768, 960):\n",
    "    inshape = (960, 768, channels)\n",
    "elif dim == (960, 1200):\n",
    "    inshape = (1200, 960, channels)\n",
    "\n",
    "base_model = ResNet18(include_top=False, input_shape=inshape)#ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=inshape, pooling=None)\n",
    "X = GlobalMaxPooling2D()(base_model.output) #average vs max? global or not?\n",
    "#X = Dense(256, activation='relu')(X)\n",
    "#X = Dropout(0.7)(X)\n",
    "\n",
    "'''\n",
    "if coord:\n",
    "    output = Dense(2, activation = 'linear')(X) \n",
    "else:\n",
    "    output = Dense(2, activation = 'sigmoid')(X) \n",
    "'''\n",
    "\n",
    "output = Dense(2, activation = 'hard_sigmoid')(X) \n",
    "    \n",
    "model = Model(base_model.inputs, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "892/892 [==============================] - 612s 686ms/step - loss: 0.0680 - val_loss: 0.0626\n",
      "Epoch 2/10\n",
      "892/892 [==============================] - 598s 670ms/step - loss: 0.0682 - val_loss: 0.0330\n",
      "Epoch 3/10\n",
      "892/892 [==============================] - 601s 673ms/step - loss: 0.0689 - val_loss: 0.0379\n",
      "Epoch 4/10\n",
      "892/892 [==============================] - 603s 676ms/step - loss: 0.0621 - val_loss: 0.0256\n",
      "Epoch 5/10\n",
      "892/892 [==============================] - 607s 680ms/step - loss: 0.0641 - val_loss: 0.0427\n",
      "Epoch 6/10\n",
      "892/892 [==============================] - 602s 675ms/step - loss: 0.0627 - val_loss: 0.0602\n",
      "Epoch 7/10\n",
      "892/892 [==============================] - 604s 677ms/step - loss: 0.0595 - val_loss: 0.0323\n",
      "Epoch 8/10\n",
      "892/892 [==============================] - 603s 676ms/step - loss: 0.0583 - val_loss: 0.1407\n",
      "Epoch 9/10\n",
      "892/892 [==============================] - 610s 684ms/step - loss: 0.0597 - val_loss: 0.0486\n",
      "Epoch 10/10\n",
      "892/892 [==============================] - 613s 687ms/step - loss: 0.0571 - val_loss: 0.0612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x636d04f10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BS = 5\n",
    "\n",
    "for layer in model.layers:\n",
    "   layer.trainable = True\n",
    "\n",
    "aug = ImageDataGenerator()#brightness_range=[0.5,1.0])#, shear_range=0.1)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "\n",
    "# train the network\n",
    "model.fit_generator(aug.flow(X_train, Y_train, batch_size=BS), validation_data=(X_test, Y_test), \n",
    "                    steps_per_epoch=len(X_train) // BS,\n",
    "                    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42488223 0.5043854 ]\n",
      " [0.54595345 0.5078617 ]\n",
      " [0.56525296 0.5088231 ]\n",
      " [0.5610737  0.5081621 ]\n",
      " [0.577561   0.507966  ]\n",
      " [0.5348729  0.5052045 ]\n",
      " [0.54681873 0.50624514]\n",
      " [0.5428157  0.5056737 ]\n",
      " [0.55398065 0.50910336]\n",
      " [0.5056326  0.5047626 ]\n",
      " [0.5558605  0.507943  ]\n",
      " [0.5417392  0.50632274]\n",
      " [0.5714761  0.51250196]\n",
      " [0.57310885 0.5112932 ]\n",
      " [0.5170821  0.5048349 ]\n",
      " [0.5403805  0.5069393 ]\n",
      " [0.52380425 0.5054019 ]\n",
      " [0.5442864  0.5058431 ]\n",
      " [0.57884336 0.5130678 ]\n",
      " [0.5419817  0.5065085 ]\n",
      " [0.5205484  0.5069448 ]\n",
      " [0.5120104  0.5074727 ]\n",
      " [0.57050544 0.5126776 ]\n",
      " [0.5352301  0.50888246]\n",
      " [0.5240589  0.5081843 ]\n",
      " [0.54203254 0.50726336]\n",
      " [0.5283079  0.5074146 ]\n",
      " [0.5639921  0.5067064 ]\n",
      " [0.5355761  0.5099543 ]\n",
      " [0.5767956  0.50783837]\n",
      " [0.5796967  0.51349145]\n",
      " [0.54990584 0.50644374]\n",
      " [0.5448568  0.5102148 ]\n",
      " [0.5199803  0.5066665 ]\n",
      " [0.48617834 0.5022276 ]\n",
      " [0.56921077 0.50832546]\n",
      " [0.5560299  0.5096616 ]\n",
      " [0.5488041  0.50744313]\n",
      " [0.522836   0.50942034]\n",
      " [0.55924803 0.51338094]\n",
      " [0.53199387 0.5080576 ]\n",
      " [0.54822075 0.50796366]\n",
      " [0.5455317  0.5081612 ]\n",
      " [0.54819876 0.508559  ]\n",
      " [0.51611495 0.5055901 ]\n",
      " [0.50012803 0.5071009 ]\n",
      " [0.53570956 0.5101141 ]\n",
      " [0.5571015  0.5106684 ]\n",
      " [0.53968686 0.5068718 ]\n",
      " [0.53597146 0.5062296 ]\n",
      " [0.5490556  0.50615793]\n",
      " [0.5556419  0.51121306]\n",
      " [0.5404798  0.50762033]\n",
      " [0.5900823  0.5114845 ]\n",
      " [0.5427804  0.5055607 ]\n",
      " [0.4755796  0.5072967 ]\n",
      " [0.56183493 0.50996095]\n",
      " [0.58674717 0.5088483 ]\n",
      " [0.55672586 0.5129628 ]\n",
      " [0.5422249  0.50986713]\n",
      " [0.51717377 0.5049812 ]\n",
      " [0.53476626 0.5062053 ]\n",
      " [0.49015483 0.50413007]\n",
      " [0.5477014  0.50671613]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(X_test)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
